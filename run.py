#!/usr/bin/env python

# based on info found here: https://pennlinc.github.io/docs/flywheel/Gear_development/

import os
import flywheel

output_dir = '/flywheel/v0/output/'

# from the gear context, get the config settings
context = flywheel.GearContext()
config = context.config

# log in to flywheel
fw = context.client

# find the analysis object this belongs to
## THIS DOES NOT WORK WHEN TESTING LOCALLY
analysis_id = context.destination['id']
analysis_container = fw.get(analysis_id)

# find the subject and session labels
session_container = fw.get(analysis_container.parent['id'])
subject_container = fw.get(session_container.parents['subject'])
project_container = fw.get(analysis_container.parents['project'])

sub_id = subject_container.label
ses_id = session_container.label
project_id = project_container.label
group_name = project_container.group

# look for the most recent run of the analysis gear D3b-ped-proc-pipeline (batch or normal version)
# gear_name = 'd3b-ped-proc-pipeline-batch'
# ses = ses_id.reload()
# analyses = ses.analyses
# if analyses:
# print(f'     {ses_id} has analysis containers')
# Check to see if any were generated by our gear
# matches = [asys for asys in analyses if asys.gear_info.get('name') == gear_name]
# Loop through the analyses and first make sure we only look at successful runs
# matches = [asys for asys in matches if asys.job.get('state')=='complete']
# print(f'     {len(matches)} completed matches for gear - {gear_name}')
# if there are none, throw an error and exit
# if len(matches) == 0:
#     print(f'>>> ERROR: no analysis containers found in this session for the gear - {gear_name}')
# # if there's only 1, that's our match
# elif len(matches) == 1:
#     match = matches[0]
# # If there are more than one matches (due to reruns), take the most recent run.
# else:
#     # Now find the max run date (most recent), and extract the analysis that has that date.
#     last_run_date = max([asys.created for asys in matches])
#     last_run_analysis = [asys for asys in matches if asys.created == last_run_date]
#     # There should only be one exact match.  If there are two successful runs that happened at the same time,
#     # Something is strange...just take one at random.
#     match = last_run_analysis[0]
# find or create the target acquisition container to save output files to
try:
    acq = fw.lookup(f'{group_name}/{project_id}/{sub_id}/{ses_id}/processed')
except:
    acq = ses_id.add_acquisition({'label':'processed'})
# now get the gear's output files & copy them to the acquisition container (renamed accordingly)
match = analysis_container.reload()
files = match.files
for file in files:
    fname = file.name
    if fname[-7:] == '.nii.gz': # if it's a nifti file
        match.download_file(fname, fname)
        base_fname = fname.split('.nii.gz')[0] # get the file name without the extension
        if 'T1CE_to_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T1CE_to_SRI.nii.gz'
        elif 'T1_to_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T1_to_SRI.nii.gz'
        elif 'T2_to_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T2_to_SRI.nii.gz'
        elif 'FL_to_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_FL_to_SRI.nii.gz'
        elif 'brainTumorSegmentation_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_pred_tumorSegmentation.nii.gz'
        elif 'brainMask_SRI' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_pred_brainMask.nii.gz'
        elif 'z_T1_to_SRI_ss' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T1_SRI_norm_ss.nii.gz'
        elif 'z_T1CE_to_SRI_ss' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T1CE_SRI_norm_ss.nii.gz'
        elif 'z_T2_to_SRI_ss' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_T2_SRI_norm_ss.nii.gz'
        elif 'z_FL_to_SRI_ss' == base_fname:
            out_fname = f'{sub_id}_{ses_id}_FL_SRI_norm_ss.nii.gz'
        else:
            out_fname == []
        if out_fname == []:
            print(f'>>> ERROR: no mapping to rename the file name - {fname}')
        else:
            os.rename(fname, out_fname)
            fw.upload_file_to_acquisition(acq.id, out_fname)
